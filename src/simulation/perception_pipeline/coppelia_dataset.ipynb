{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Capture from Coppelia Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LD_LIBRARY_PATH LD_LIBRARY_PATH\n",
      "QT_QPA_PLATFORM_PLUGIN_PATH QT_QPA_PLATFORM_PLUGIN_PATH\n",
      "\n",
      "dataset capture (./datasets/dualarms_3cam/dualarms_3cam.pkl) using PyRep started!\n",
      "dataset successfully output in:  ./datasets/dualarms_3cam/dualarms_3cam.pkl\n"
     ]
    }
   ],
   "source": [
    "# if using .py: need to set environment variables->\n",
    "# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$COPPELIASIM_ROOT\n",
    "# export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT\n",
    "# cd $COPPELIASIM_ROOT && ./coppeliaSim.sh\n",
    "\n",
    "# if using .ipynb (Jupyter): need to config variables in kernel configs -> \n",
    "# https://stackoverflow.com/questions/73110604/vs-code-jupyter-integration-does-not-consider-custom-ld-library-path\n",
    "# \"env\": {\"LD_LIBRARY_PATH\": \"/home/dev/ws_coppelia/coppeliasim\", \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/home/dev/ws_coppelia/coppeliasim\"}\n",
    "\n",
    "import os, sys, time, pickle\n",
    "LD_LIBRARY_PATH = 'LD_LIBRARY_PATH'\n",
    "QT_QPA_PLATFORM_PLUGIN_PATH = 'QT_QPA_PLATFORM_PLUGIN_PATH'\n",
    "print('LD_LIBRARY_PATH', LD_LIBRARY_PATH)\n",
    "print('QT_QPA_PLATFORM_PLUGIN_PATH', QT_QPA_PLATFORM_PLUGIN_PATH)\n",
    "assert LD_LIBRARY_PATH, \"LD_LIBRARY_PATH needs to be set!\"\n",
    "assert QT_QPA_PLATFORM_PLUGIN_PATH, \"QT_QPA_PLATFORM_PLUGIN_PATH needs to be set!\"\n",
    "\n",
    "from pyrep import PyRep\n",
    "from pyrep.robots.arms.arm import Arm\n",
    "from pyrep.objects import VisionSensor\n",
    "\n",
    "PROJECT_NAME = 'dualarms_3cam'\n",
    "SCENE = f'./scenes/{PROJECT_NAME}.ttt'\n",
    "DATASET_SAVE_FILEPATH = f'./datasets/{PROJECT_NAME}/{PROJECT_NAME}.pkl'\n",
    "SIMULATION_TIME = 2.0\n",
    "HEADLESS    = True\n",
    "IMAGE_SIZE  = 240\n",
    "ARM_NAME = 'panda'\n",
    "CAMERAS = ['cam1', 'cam2', 'cam3']\n",
    "\n",
    "\n",
    "# setup and launch scene\n",
    "pr = PyRep()\n",
    "pr.launch(\n",
    "    SCENE, \n",
    "    headless=HEADLESS,) \n",
    "pr.start() \n",
    "\n",
    "\n",
    "# wrapper for agents\n",
    "class ArmWrapper(Arm):\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: str,\n",
    "        count: int = 0\n",
    "    ):\n",
    "        super().__init__(count, name, 7)  \n",
    "        self.name = f'{name}{count}'\n",
    "\n",
    "# setup agents\n",
    "# from Pyrep's robots/arms/arm.py\n",
    "# suffix = '' if count == 0 else '#%d' % (count - 1) \n",
    "agent1 = ArmWrapper(ARM_NAME,)\n",
    "agent2 = ArmWrapper(ARM_NAME, count=1) \n",
    "\n",
    "agent_dict = dict(arms=[\n",
    "    agent1, \n",
    "    agent2\n",
    "])\n",
    "\n",
    "\n",
    "class Observer():\n",
    "    def __init__(\n",
    "        self,\n",
    "        CAMERA_NAMES:list,\n",
    "        IMAGE_SIZE:int,\n",
    "        AGENTS:dict,\n",
    "    ):\n",
    "        # setup cameras\n",
    "        self.CAMERA_NAMES   = CAMERA_NAMES\n",
    "        self.cameras    = dict()\n",
    "        self.IMAGE_SIZE = IMAGE_SIZE\n",
    "\n",
    "        # setup cameras and set resolution\n",
    "        for cam_name in CAMERAS:\n",
    "            cam = VisionSensor(cam_name)  \n",
    "            cam.set_resolution([IMAGE_SIZE,IMAGE_SIZE])\n",
    "            self.cameras[cam_name] = cam\n",
    "\n",
    "        # list for storing observations\n",
    "        self.observations = list()\n",
    "\n",
    "        # setup agents\n",
    "        self.agents = AGENTS\n",
    "\n",
    "    def store_new_observation(self) -> None:\n",
    "        obs = dict()\n",
    "        \n",
    "        # store cam obs\n",
    "        for cam_name, cam in self.cameras.items():\n",
    "            obs[cam_name] = self.get_camera_observation(cam) \n",
    "\n",
    "        # store arm joints obs\n",
    "        for agent in self.agents['arms']:\n",
    "            obs[agent.name] = self.get_agent_observation(agent)\n",
    "\n",
    "        # store observation\n",
    "        self.observations.append(obs)\n",
    "\n",
    "    def get_agent_observation(self, agent) -> dict:\n",
    "        joint_pos = agent.get_joint_positions()\n",
    "        global_pos = agent.get_position()\n",
    "        global_ang = agent.get_orientation()\n",
    "        return dict( \n",
    "            joint_pos = joint_pos,\n",
    "            global_pos = global_pos,\n",
    "            global_ang = global_ang,\n",
    "        )\n",
    "\n",
    "    def get_camera_observation(self, cam:VisionSensor) -> dict:\n",
    "        rgb = cam.capture_rgb()\n",
    "        depth = cam.capture_depth()\n",
    "        position = cam.get_position()\n",
    "        resolution = cam.get_resolution()\n",
    "        extrinsics = cam.get_matrix()\n",
    "        intrinsics = cam.get_intrinsic_matrix()\n",
    "        pointcloud = cam.capture_pointcloud()\n",
    "\n",
    "        return dict(\n",
    "            rgb=rgb,\n",
    "            depth=depth,\n",
    "            position=position,\n",
    "            resolution=resolution,\n",
    "            extrinsics=extrinsics,\n",
    "            intrinsics=intrinsics,\n",
    "            pointcloud=pointcloud)\n",
    "\n",
    "    def save_observations(self, filepath:str) -> None:\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.observations, f)\n",
    "\n",
    "\n",
    "# setup observer\n",
    "observer_handle = Observer(\n",
    "    CAMERAS,\n",
    "    IMAGE_SIZE,\n",
    "    agent_dict,\n",
    ")\n",
    "\n",
    "print(f'\\ndataset capture ({DATASET_SAVE_FILEPATH}) using PyRep started!')\n",
    "# run simulation\n",
    "start_time = time.time()\n",
    "while (time.time() - start_time) < SIMULATION_TIME:\n",
    "\n",
    "    # capture obs\n",
    "    observer_handle.store_new_observation()\n",
    "\n",
    "    # step simulation\n",
    "    pr.step()\n",
    "\n",
    "# save dataset\n",
    "observer_handle.save_observations(DATASET_SAVE_FILEPATH)\n",
    "print('dataset successfully output in: ', DATASET_SAVE_FILEPATH)\n",
    "\n",
    "pr.stop()\n",
    "pr.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perception Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES:\n",
    "# \"Vision Sensor\" - In Coppelia scene (.ttt file) the \"Vision sensor\" is a generic sensor and a real world application would require appropriate calculations. \n",
    "# \"Manual Offset for RBS URDF\" - Manual offset for base of URDF required due to Coppelia Sim version 4.1.0. \n",
    "# Later versions don't require this offset but PyRep does not support those versions of coppelia Sim.\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICP (GPU) [sec]: 0.037661075592041016\n",
      "ICP (GPU) [sec]: 0.04591488838195801\n",
      "Agent: panda0\n",
      "empty mesh detected, skipped\n",
      "empty mesh detected, skipped\n",
      "RBS (CPU+GPU) [sec]: 0.0236051082611084\n",
      "Agent: panda1\n",
      "empty mesh detected, skipped\n",
      "empty mesh detected, skipped\n",
      "RBS (CPU+GPU) [sec]: 0.021513938903808594\n",
      "Voxelization (GPU) [sec]: 0.003942012786865234\n",
      "Voxel2Sphere (CPU) [sec]: 0.014079093933105469\n"
     ]
    }
   ],
   "source": [
    "# Root of Project\n",
    "ROOT = '/home/dev/ws_percept/src'\n",
    "\n",
    "# # Cameras\n",
    "# IMAGE_SIZE  = 240\n",
    "# CAMERAS = ['cam1', 'cam2', 'cam3']\n",
    "\n",
    "# Scene\n",
    "# [x_min, y_min, z_min, x_max, y_max, z_max] - the metric volume to be voxelized\n",
    "SCENE_BOUNDS    = (-1.5, -1.5, -1.5, 1.50, 1.5, 1.5)\n",
    "\n",
    "# Agents\n",
    "AGENTS = [f'{ARM_NAME}0', f'{ARM_NAME}1']\n",
    "\n",
    "SHOW_CPH_VIZ = False\n",
    "\n",
    "ROBOT_URDF_PATH = 'outputs/testdata/franka_panda_cupoch/panda.urdf'\n",
    "URDF_JOINT_PREFIX = 'panda_joint'\n",
    "\n",
    "CUBIC_SIZE = 2.0\n",
    "VOXEL_RESOLUTION = 30.0 # = 100.0\n",
    "SPHERICAL_RADIUS = 0.03\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import cupoch as cph\n",
    "\n",
    "\n",
    "class PerceptionPipeline():\n",
    "    def __init__(self):\n",
    "        self.observations = None\n",
    "        self.obs = None\n",
    "        self.pcds = None\n",
    "        self.pcd = None\n",
    "        self.kin = None\n",
    "        self.meshes_list = None\n",
    "        self.voxels = None\n",
    "        self.voxel_size = None\n",
    "        self.v2s_positions = None\n",
    "        self.spheres = None\n",
    "\n",
    "    def load_dataset(self, DATASET_PATH) -> None:\n",
    "        with open(DATASET_PATH, 'rb') as f:\n",
    "            self.observations = pickle.load(f)\n",
    "\n",
    "    def select_obs(self, n:int=1) -> None:\n",
    "        self.obs = self.observations[n]\n",
    "        self.get_pcds_for_registration()\n",
    "\n",
    "    \"\"\"\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "        Get Pointclouds\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    \"\"\"\n",
    "\n",
    "    def constrain_scene_bounds(self, data) -> np.array:\n",
    "        global SCENE_BOUNDS\n",
    "        nX, nY, nZ, X, Y, Z = SCENE_BOUNDS\n",
    "        X_mask = (data[:,0] > nX) & (data[:,0]<X)\n",
    "        Y_mask = (data[:,1] > nY) & (data[:,1]<Y)\n",
    "        Z_mask = (data[:,2] > nZ) & (data[:,2]<Z)\n",
    "        mask = (X_mask)&(Y_mask)&(Z_mask) \n",
    "        return data[mask]\n",
    "\n",
    "    def get_pcd_and_rgb(self, camera_obs:dict) -> tuple:\n",
    "        pcd = camera_obs['pointcloud'].reshape(-2,3)\n",
    "        rgb = camera_obs['rgb'].reshape(-2,3)\n",
    "        return pcd, rgb\n",
    "    \n",
    "    def get_pcds_for_registration(self) -> None:\n",
    "        global CAMERAS\n",
    "        obs = self.obs\n",
    "        assert obs is not None, \"Did you select the obs?\"\n",
    "\n",
    "        pcds = list()\n",
    "        for CAMERA in CAMERAS:\n",
    "            camera_obs = obs[CAMERA]\n",
    "            pcd, rgb = self.get_pcd_and_rgb(camera_obs)\n",
    "            pcd = self.constrain_scene_bounds(pcd)\n",
    "            pcds.append(pcd)\n",
    "\n",
    "        # return pcds\n",
    "        self.pcds = pcds\n",
    "\n",
    "    def do_point_cloud_registration(\n",
    "        self\n",
    "    ) -> None: #cph.geometry.PointCloud:\n",
    "\n",
    "        pcds = self.pcds\n",
    "        assert pcds is not None, \"Did you get the pcds?\"\n",
    "        assert len(pcds) > 1, \"Are you using only 1 camera?\"\n",
    "\n",
    "        def register(\n",
    "            source_gpu:cph.geometry.PointCloud, \n",
    "            target_gpu:cph.geometry.PointCloud,\n",
    "        ) -> cph.geometry.PointCloud:\n",
    "\n",
    "            threshold = 0.02 # what does this do?\n",
    "            trans_init = np.asarray([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0],\n",
    "                                    [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "            # register pointclouds\n",
    "            start = time.time()\n",
    "            reg_p2p = cph.registration.registration_icp(\n",
    "                source_gpu,\n",
    "                target_gpu,\n",
    "                threshold,\n",
    "                trans_init.astype(np.float32),\n",
    "                cph.registration.TransformationEstimationPointToPlane(),\n",
    "            )\n",
    "\n",
    "            source_gpu.transform(reg_p2p.transformation)\n",
    "\n",
    "            # remove outliers\n",
    "            NEIGHBOURS = 2\n",
    "            source_gpu, ind = source_gpu.remove_statistical_outlier(nb_neighbors=NEIGHBOURS, std_ratio=2.0)\n",
    "            target_gpu, ind = target_gpu.remove_statistical_outlier(nb_neighbors=NEIGHBOURS, std_ratio=2.0)\n",
    "\n",
    "\n",
    "            elapsed_time = time.time() - start\n",
    "            print(\"ICP (GPU) [sec]:\", elapsed_time) # adding outlier removal adds ~25ms\n",
    "        \n",
    "            return source_gpu+target_gpu\n",
    "\n",
    "\n",
    "        # load first and second pcd\n",
    "        source_gpu = cph.geometry.PointCloud(\n",
    "            cph.utility.HostVector3fVector(pcds[0])\n",
    "        )\n",
    "        target_gpu = cph.geometry.PointCloud(\n",
    "            cph.utility.HostVector3fVector(pcds[1])\n",
    "        )\n",
    "        # register pcds\n",
    "        source_gpu = register(source_gpu, target_gpu)\n",
    "\n",
    "        # merge all other pcds with new source\n",
    "        for pcd in pcds[2:]:\n",
    "            target_gpu = cph.geometry.PointCloud(\n",
    "                cph.utility.HostVector3fVector(pcd)\n",
    "            )\n",
    "            source_gpu = register(source_gpu, target_gpu)\n",
    "        # return source_gpu\n",
    "        self.pcd = source_gpu\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "        Do Robot Body Subtraction\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    \"\"\"\n",
    "    def get_tf_matrix(\n",
    "        self,\n",
    "        translation:np.array,\n",
    "        rotation:np.array, \n",
    "    ) -> np.array:\n",
    "\n",
    "        r = R.from_rotvec(rotation)\n",
    "        r = r.as_matrix()\n",
    "\n",
    "        tf = np.eye(4)\n",
    "        tf[:3,:3] = r\n",
    "        tf[:3,3] = translation\n",
    "\n",
    "        return tf\n",
    "\n",
    "    def manually_offset_base(   # used only for coppelia 4.1.0\n",
    "        self,\n",
    "        ref:np.array, \n",
    "        translation_offset\n",
    "    ) -> np.array:\n",
    "        offset = np.eye(4)\n",
    "        offset[:3, 3] = translation_offset\n",
    "        return np.dot(ref, offset)\n",
    "\n",
    "    def get_mesh_using_forward_kinematics(\n",
    "        self,\n",
    "        joints_positions:np.array,\n",
    "        global_position:np.array,\n",
    "        global_rotation:np.array\n",
    "    ):\n",
    "        global URDF_JOINT_PREFIX, ROOT, ROBOT_URDF_PATH\n",
    "\n",
    "        # load URDF model\n",
    "        path = os.path.join(ROOT, ROBOT_URDF_PATH)\n",
    "        self.kin = cph.kinematics.KinematicChain(path)\n",
    "\n",
    "        # create joint_map, used for fk on urdf model\n",
    "        joint_map = {'%s%d' % (URDF_JOINT_PREFIX, i+1): val for i, val \\\n",
    "                    in enumerate(joints_positions)} \n",
    "\n",
    "        # create transformation matrix\n",
    "        tf_matrix = self.get_tf_matrix(global_position, global_rotation)\n",
    "\n",
    "        # manual offset, to be removed \n",
    "        offset = np.array([0.04, 0.0, -0.068])\n",
    "        tf_matrix = self.manually_offset_base(tf_matrix, offset)\n",
    "        \n",
    "        # do forward kinematics\n",
    "        poses = self.kin.forward_kinematics(joint_map, tf_matrix)\n",
    "        \n",
    "        # store mesh geometries\n",
    "        meshes = self.kin.get_transformed_visual_geometry_map(poses)\n",
    "        \n",
    "        return list(meshes.values())\n",
    "\n",
    "    def get_bb_from_mesh(\n",
    "        self,\n",
    "        mesh:cph.geometry.TriangleMesh\n",
    "    ) -> cph.geometry.AxisAlignedBoundingBox:\n",
    "\n",
    "        AABB = mesh.get_axis_aligned_bounding_box()\n",
    "        if AABB.is_empty():\n",
    "            print('empty mesh detected, skipped')\n",
    "            return None       \n",
    "        else:\n",
    "            return AABB\n",
    "\n",
    "\n",
    "    def perform_rbs_on_pointcloud_using_bb(\n",
    "        self, \n",
    "    )->tuple:\n",
    "        obs = self.obs\n",
    "        pcd = self.pcd\n",
    "\n",
    "        assert obs is not None, \"Did you get select the obs?\"\n",
    "        assert pcd is not None, \"Did you perform PCD registration?\"\n",
    "\n",
    "        n = len(pcd.points)\n",
    "        masks = list()\n",
    "        meshes_list = list()\n",
    "        for agent in AGENTS:\n",
    "            print('Agent: %s' % agent)\n",
    "            agent_obs = obs[agent]\n",
    "            \n",
    "            # get all meshes of the agent using fk\n",
    "            meshes = self.get_mesh_using_forward_kinematics(\n",
    "                agent_obs['joint_pos'],\n",
    "                agent_obs['global_pos'],\n",
    "                agent_obs['global_ang'],\n",
    "            )\n",
    "            meshes_list += meshes\n",
    "\n",
    "            # find points within BBs and create masks\n",
    "            start = time.time()\n",
    "            for mesh in meshes:\n",
    "                bb = self.get_bb_from_mesh(mesh)\n",
    "\n",
    "                if bb is not None:\n",
    "                    mask = np.zeros(n, dtype=bool)\n",
    "\n",
    "                    indices_points_within_bb = np.asarray(\n",
    "                        bb.get_point_indices_within_bounding_box(\n",
    "                            pcd.points\n",
    "                        ).cpu()\n",
    "                    )\n",
    "                    if len(indices_points_within_bb)>0:\n",
    "                        mask[indices_points_within_bb] = True\n",
    "                        masks.append(mask)\n",
    "\n",
    "            elapsed_time = time.time() - start\n",
    "            print(\"RBS (CPU+GPU) [sec]:\", elapsed_time)\n",
    "\n",
    "\n",
    "        mask = np.column_stack(tuple(masks)).any(axis=1)\n",
    "        mask = ~mask # inverting mask to get pcd which were not within any BBs\n",
    "        \n",
    "        pcd_arr = np.asarray(pcd.points.cpu())\n",
    "        NEIGHBOURS = 10\n",
    "        pcd = cph.geometry.PointCloud(cph.utility.HostVector3fVector(pcd_arr[mask]))\n",
    "        pcd = pcd.remove_statistical_outlier(nb_neighbors=NEIGHBOURS, std_ratio=1.0)\n",
    "        # return  pcd[0], meshes_list\n",
    "        self.pcd = pcd[0] \n",
    "        self.meshes_list = meshes_list\n",
    "\n",
    "    \"\"\"\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "        Voxelization\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    \"\"\"\n",
    "    def convert_pointcloud_to_voxels(self):\n",
    "        global CUBIC_SIZE, VOXEL_RESOLUTION\n",
    "        cubic_size = CUBIC_SIZE\n",
    "        voxel_resolution = VOXEL_RESOLUTION\n",
    "        voxel_size = cubic_size / voxel_resolution\n",
    "\n",
    "        pcd = self.pcd\n",
    "        assert pcd is not None, \"Did you do Point Cloud Registration?\"\n",
    "\n",
    "        # create voxel grid\n",
    "        start = time.time()\n",
    "        voxels = cph.geometry.VoxelGrid.create_from_point_cloud_within_bounds(\n",
    "            pcd,\n",
    "            voxel_size=cubic_size / voxel_resolution,\n",
    "            min_bound=(-cubic_size / 2, -cubic_size / 2, -cubic_size / 2),\n",
    "            max_bound=(cubic_size / 2, cubic_size / 2, cubic_size / 2),\n",
    "        )\n",
    "        elapsed_time = time.time() - start\n",
    "        print(\"Voxelization (GPU) [sec]:\", elapsed_time) # adding outlier removal adds ~25ms\n",
    "\n",
    "        # return voxels, voxel_size\n",
    "        self.voxels = voxels\n",
    "        self.voxel_size = voxel_size\n",
    "\n",
    "    \"\"\"\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "        V2S - Voxel To Sphere\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    \"\"\"\n",
    "    def voxel2sphere(self) -> None:\n",
    "        voxel_size = self.voxel_size\n",
    "        voxels = self.voxels\n",
    "        \n",
    "        assert voxel_size is not None, \"Did you not convert pcd to voxels?\"\n",
    "        assert voxels is not None, \"Did you not convert pcd to voxels?\"\n",
    "\n",
    "        start = time.time()\n",
    "        v = voxels.voxels.cpu()\n",
    "        offset = voxels.get_min_bound()\n",
    "        positions = np.array(list(v.keys()))\n",
    "        positions = (positions - np.array([\n",
    "                        min(positions[:,0]), \n",
    "                        min(positions[:,1]), \n",
    "                        min(positions[:,2])]))\n",
    "        positions = positions*voxel_size\n",
    "        positions += (offset + voxel_size/2)\n",
    "\n",
    "        elapsed_time = time.time() - start\n",
    "        print(\"Voxel2Sphere (CPU) [sec]:\", elapsed_time) # adding outlier removal adds ~25ms\n",
    "\n",
    "        self.v2s_positions = positions\n",
    "\n",
    "    def get_sphere_viz(self, meshcolor:bool=True):\n",
    "        global SPHERICAL_RADIUS\n",
    "        voxels = self.voxels\n",
    "        voxel_size = self.voxel_size\n",
    "        radius = SPHERICAL_RADIUS\n",
    "        resolution = 5\n",
    "        positions = self.v2s_positions\n",
    "\n",
    "        assert positions is not None, \"Did you convert Voxels to Spheres (V2S)?\"\n",
    "\n",
    "        spheres = cph.geometry.TriangleMesh.create_sphere(\n",
    "            radius=radius, \n",
    "            resolution=resolution).translate(positions[0])\n",
    "        for pos in positions[1:]:\n",
    "            spheres += cph.geometry.TriangleMesh.create_sphere(\n",
    "                radius=radius, \n",
    "                resolution=resolution).translate(pos)\n",
    "\n",
    "        if meshcolor:\n",
    "            import matplotlib.pyplot as plt\n",
    "            vertices = np.asarray(spheres.vertices.cpu())\n",
    "            z_values = vertices[:, 2]\n",
    "\n",
    "            # Normalize the z values to range [0, 1]\n",
    "            z_min = z_values.min()\n",
    "            z_max = z_values.max()\n",
    "            z_norm = (z_values - z_min) / (z_max - z_min)\n",
    "\n",
    "            # Create a color map (using a matplotlib colormap, e.g., 'viridis')\n",
    "            cmap = plt.get_cmap('turbo')\n",
    "            colors = cmap(z_norm)[:, :3]  # Get RGB values\n",
    "\n",
    "            # Apply the colors to the mesh\n",
    "            spheres.vertex_colors = cph.utility.Vector3fVector(colors)\n",
    "        self.spheres = spheres\n",
    "\n",
    "    def run(self):\n",
    "        global DATASET_SAVE_FILEPATH\n",
    "        self.load_dataset(DATASET_SAVE_FILEPATH)\n",
    "        self.select_obs(1)\n",
    "        self.do_point_cloud_registration()\n",
    "        self.perform_rbs_on_pointcloud_using_bb()\n",
    "        self.convert_pointcloud_to_voxels()\n",
    "        self.voxel2sphere()\n",
    "\n",
    "\n",
    "pipe = PerceptionPipeline()\n",
    "pipe.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_sphere_viz()\n",
    "cph.visualization.draw_geometries([pipe.spheres])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAML Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPHERICAL_RADIUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# YAML_FILE_BASENAME = 'dual_arms_static3'\n",
    "# YAML_OUTPUT_FILE = f'./datasets/{PROJECT_NAME}/{YAML_FILE_BASENAME}.yaml'\n",
    "\n",
    "YAML_OUTPUT_FILE = '/home/dev/catkin_ws/pmaf_ws/src/bimanual_planning_ros/config/tasks/dual_arms_static3.yaml'\n",
    "\n",
    "class YAMLObstacles():\n",
    "    def __init__(self):\n",
    "        self.vel = [0.0, 0.0, 0.0]\n",
    "        self.isep = '  '\n",
    "        self.osep = '      '\n",
    "\n",
    "    def dump_item(self, pos:np.array, radius:float):\n",
    "\n",
    "        string = f\"{self.osep}- pos: {(pos+np.array([0.40, -0.1,0.0])).tolist()}\"\n",
    "        string += f\"\\n{self.osep}{self.isep}radius: {radius}\"\n",
    "        string += f\"\\n{self.osep}{self.isep}vel: {self.vel}\"\n",
    "        return string\n",
    "    \n",
    "    def output_to_yaml_file(\n",
    "        self, \n",
    "        obstacle_positions:np.array,\n",
    "        radius:float,\n",
    "        read_until:int= 1742\n",
    "    ) -> None:\n",
    "        global YAML_OUTPUT_FILE\n",
    "        yaml_str = \"      obstacles:\\n\"\n",
    "        for pos in obstacle_positions:\n",
    "            yaml_str += self.dump_item(pos, radius)\n",
    "            yaml_str += '\\n'\n",
    "        # print(yaml_str)\n",
    "\n",
    "        contents = None\n",
    "        with open(YAML_OUTPUT_FILE, 'r') as file:\n",
    "            contents = file.read()\n",
    "\n",
    "        with open(YAML_OUTPUT_FILE, 'w+') as f:\n",
    "            f.write(contents[:read_until]+\"\\n\"+yaml_str)\n",
    "\n",
    "\n",
    "\n",
    "yaml_obstacles = YAMLObstacles()\n",
    "yaml_obstacles.output_to_yaml_file(pipe.v2s_positions, SPHERICAL_RADIUS*1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal_pos: [0.05, 0.0, 0.45]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peract_env_ldconf",
   "language": "python",
   "name": "peract_env_ldconf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
