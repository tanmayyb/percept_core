{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root of Project\n",
    "ROOT = '/home/dev/ws_percept/src'\n",
    "\n",
    "# Cameras\n",
    "IMAGE_SIZE  = 240\n",
    "CAMERAS = ['cam1', 'cam2', 'cam3']\n",
    "\n",
    "# Scene\n",
    "# [x_min, y_min, z_min, x_max, y_max, z_max] - the metric volume to be voxelized\n",
    "SCENE_BOUNDS    = (-1.5, -1.5, -1.5, 1.50, 1.5, 1.5)\n",
    "\n",
    "# Agents\n",
    "AGENTS = ['panda0', 'panda1']\n",
    "\n",
    "SHOW_CPH_VIZ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "DATASET_PATH = '../outputs/dualarms_3cam/dualarms_3cam_with_fk.pkl'\n",
    "with open(DATASET_PATH, 'rb') as f:\n",
    "    _obs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PCD, Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain_scene_bounds(data):\n",
    "    global SCENE_BOUNDS\n",
    "\n",
    "    nX, nY, nZ, X, Y, Z = SCENE_BOUNDS\n",
    "\n",
    "    X_mask = (data[:,0] > nX) & (data[:,0]<X)\n",
    "    Y_mask = (data[:,1] > nY) & (data[:,1]<Y)\n",
    "    Z_mask = (data[:,2] > nZ) & (data[:,2]<Z)\n",
    "    mask = (X_mask)&(Y_mask)&(Z_mask) \n",
    "\n",
    "    return data[mask]\n",
    "\n",
    "def get_pcd_and_rgb(camera_obs:dict):\n",
    "    pcd = camera_obs['pointcloud'].reshape(-2,3)\n",
    "    rgb = camera_obs['rgb'].reshape(-2,3)\n",
    "    return pcd, rgb\n",
    "\n",
    "def get_pcd(camera_obs:dict):\n",
    "    pcd = camera_obs['pointcloud'].reshape(-2,3)\n",
    "    return pcd\n",
    "\n",
    "\n",
    "obs = _obs[-1]\n",
    "camera_obs = obs[CAMERAS[0]]\n",
    "pcd, rgb = get_pcd_and_rgb(camera_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-27 17:15:40.281] [warning] Read OBJ failed: Material file [ link0.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.652] [warning] Read OBJ failed: Material file [ link0.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.653] [warning] Read OBJ failed: Material file [ link1.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.681] [warning] Read OBJ failed: Material file [ link2.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.706] [warning] Read OBJ failed: Material file [ link3.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.739] [warning] Read OBJ failed: Material file [ link4.stl.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.776] [warning] Read OBJ failed: Material file [ link5.stl.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.868] [warning] Read OBJ failed: Material file [ link7.stl.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.874] [warning] Read OBJ failed: Material file [ link7.stl.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.876] [warning] Read OBJ failed: Material file [ hand.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.907] [warning] Read OBJ failed: Material file [ finger.stl.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n",
      "[2024-08-27 17:15:40.927] [warning] Read OBJ failed: Material file [ finger.stl.obj.mtl ] not found in a path : /home/dev/ws_percept/src/outputs/testdata/franka_panda_cupoch/meshes/collision/\n",
      "Failed to load material file(s). Use default material.\n",
      "material [ 'DefaultMaterial' ] not found in .mtl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "import cupoch as cph\n",
    "\n",
    "ROBOT_URDF_PATH = 'outputs/testdata/franka_panda_cupoch/panda.urdf'\n",
    "URDF_JOINT_PREFIX = 'panda_joint'\n",
    "\n",
    "path = os.path.join(ROOT, ROBOT_URDF_PATH)\n",
    "kin = cph.kinematics.KinematicChain(path)\n",
    "\n",
    "\n",
    "def get_tf_matrix(\n",
    "    translation:np.array,\n",
    "    rotation:np.array, \n",
    ") -> np.array:\n",
    "\n",
    "    r = R.from_rotvec(rotation)\n",
    "    r = r.as_matrix()\n",
    "\n",
    "    tf = np.eye(4)\n",
    "    tf[:3,:3] = r\n",
    "    tf[:3,3] = translation\n",
    "\n",
    "    return tf\n",
    "\n",
    "def manually_offset_base(ref:np.array, translation_offset) -> np.array:\n",
    "    offset = np.eye(4)\n",
    "    offset[:3, 3] = translation_offset\n",
    "    return np.dot(ref, offset)\n",
    "\n",
    "def get_mesh_using_forward_kinematics(\n",
    "    joints_positions:np.array,\n",
    "    global_position:np.array,\n",
    "    global_rotation:np.array\n",
    "):\n",
    "    global URDF_JOINT_PREFIX\n",
    "\n",
    "    # create joint_map, used for fk on urdf model\n",
    "    joint_map = {'%s%d' % (URDF_JOINT_PREFIX, i+1): val for i, val \\\n",
    "                in enumerate(joints_positions)} \n",
    "\n",
    "    # create transformation matrix\n",
    "    tf_matrix = get_tf_matrix(global_position, global_rotation)\n",
    "\n",
    "    # manual offset, to be removed \n",
    "    offset = np.array([0.04, 0.0, -0.068])\n",
    "    tf_matrix = manually_offset_base(tf_matrix, offset)\n",
    "    \n",
    "    # do forward kinematics\n",
    "    poses = kin.forward_kinematics(joint_map, tf_matrix)\n",
    "    \n",
    "    # store mesh geometries\n",
    "    meshes = kin.get_transformed_visual_geometry_map(poses)\n",
    "    \n",
    "    return list(meshes.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcds_for_registration(obs):\n",
    "    global CAMERAS\n",
    "\n",
    "    pcds = list()\n",
    "    for CAMERA in CAMERAS:\n",
    "        camera_obs = obs[CAMERA]\n",
    "        pcd, rgb = get_pcd_and_rgb(camera_obs)\n",
    "        pcd = constrain_scene_bounds(pcd)\n",
    "        pcds.append(pcd)\n",
    "\n",
    "    return pcds\n",
    "\n",
    "pcds = get_pcds_for_registration(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-27 17:15:41.126] [error] TransformationEstimationPointToPlane and TransformationEstimationColoredICP require pre-computed target normal vectors.\n",
      "ICP (GPU) [sec]: 0.03101515769958496\n",
      "[2024-08-27 17:15:41.244] [error] TransformationEstimationPointToPlane and TransformationEstimationColoredICP require pre-computed target normal vectors.\n",
      "ICP (GPU) [sec]: 0.029599428176879883\n"
     ]
    }
   ],
   "source": [
    "def do_point_cloud_registration(pcds):\n",
    "    assert len(pcds) > 1\n",
    "    def register(\n",
    "        source_gpu:cph.geometry.PointCloud, \n",
    "        target_gpu:cph.geometry.PointCloud,\n",
    "    ) -> cph.geometry.PointCloud:\n",
    "\n",
    "        threshold = 0.02 # what does this do?\n",
    "        trans_init = np.asarray([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0],\n",
    "                                [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "        # register pointclouds\n",
    "        start = time.time()\n",
    "        reg_p2p = cph.registration.registration_icp(\n",
    "            source_gpu,\n",
    "            target_gpu,\n",
    "            threshold,\n",
    "            trans_init.astype(np.float32),\n",
    "            cph.registration.TransformationEstimationPointToPlane(),\n",
    "        )\n",
    "\n",
    "        source_gpu.transform(reg_p2p.transformation)\n",
    "\n",
    "        # remove outliers\n",
    "        NEIGHBOURS = 2\n",
    "        source_gpu, ind = source_gpu.remove_statistical_outlier(nb_neighbors=NEIGHBOURS, std_ratio=2.0)\n",
    "        target_gpu, ind = target_gpu.remove_statistical_outlier(nb_neighbors=NEIGHBOURS, std_ratio=2.0)\n",
    "\n",
    "\n",
    "        elapsed_time = time.time() - start\n",
    "        print(\"ICP (GPU) [sec]:\", elapsed_time) # adding outlier removal adds ~25ms\n",
    "    \n",
    "        return source_gpu+target_gpu\n",
    "\n",
    "\n",
    "    # load first and second pcd\n",
    "    source_gpu = cph.geometry.PointCloud(\n",
    "        cph.utility.HostVector3fVector(pcds[0])\n",
    "    )\n",
    "    target_gpu = cph.geometry.PointCloud(\n",
    "        cph.utility.HostVector3fVector(pcds[1])\n",
    "    )\n",
    "    source_gpu = register(source_gpu, target_gpu)\n",
    "\n",
    "    # merge all other pcds with new source\n",
    "    for pcd in pcds[2:]:\n",
    "        target_gpu = cph.geometry.PointCloud(\n",
    "            cph.utility.HostVector3fVector(pcd)\n",
    "        )\n",
    "        source_gpu = register(source_gpu, target_gpu)\n",
    "\n",
    "\n",
    "    return source_gpu\n",
    "\n",
    "\n",
    "pcd = do_point_cloud_registration(pcds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: panda0\n",
      "empty mesh detected\n",
      "empty mesh detected\n",
      "RBS (CPU+GPU) [sec]: 0.01578044891357422\n",
      "\n",
      "Agent: panda1\n",
      "empty mesh detected\n",
      "empty mesh detected\n",
      "RBS (CPU+GPU) [sec]: 0.012721776962280273\n"
     ]
    }
   ],
   "source": [
    "def get_bb_from_mesh(\n",
    "    mesh:cph.geometry.TriangleMesh\n",
    ") -> cph.geometry.AxisAlignedBoundingBox:\n",
    "\n",
    "    AABB = mesh.get_axis_aligned_bounding_box()\n",
    "    if AABB.is_empty():\n",
    "        print('empty mesh detected')\n",
    "        return None       \n",
    "    else:\n",
    "        return AABB\n",
    "    \n",
    "\n",
    "def perform_rbs_on_pointcloud_using_bb(obs, pcd):\n",
    "\n",
    "    n = len(pcd.points)\n",
    "    masks = list()\n",
    "    meshes_list = list()\n",
    "    for agent in AGENTS:\n",
    "        print('\\nAgent: %s' % agent)\n",
    "        agent_obs = obs[agent]\n",
    "        \n",
    "        # get all meshes of the agent using fk\n",
    "        meshes = get_mesh_using_forward_kinematics(\n",
    "            agent_obs['joint_pos'],\n",
    "            agent_obs['global_pos'],\n",
    "            agent_obs['global_ang'],\n",
    "        )\n",
    "        meshes_list += meshes\n",
    "\n",
    "        # find points within BBs and create masks\n",
    "        start = time.time()\n",
    "        for mesh in meshes:\n",
    "            bb = get_bb_from_mesh(mesh)\n",
    "\n",
    "            if bb is not None:\n",
    "                mask = np.zeros(n, dtype=bool)\n",
    "\n",
    "                indices_points_within_bb = np.asarray(\n",
    "                    bb.get_point_indices_within_bounding_box(\n",
    "                        pcd.points\n",
    "                    ).cpu()\n",
    "                )\n",
    "                if len(indices_points_within_bb)>0:\n",
    "                    mask[indices_points_within_bb] = True\n",
    "                    masks.append(mask)\n",
    "\n",
    "        elapsed_time = time.time() - start\n",
    "        print(\"RBS (CPU+GPU) [sec]:\", elapsed_time)\n",
    "\n",
    "\n",
    "    mask = np.column_stack(tuple(masks)).any(axis=1)\n",
    "    mask = ~mask # inverting mask to get pcd which were not within any BBs\n",
    "    \n",
    "    pcd_arr = np.asarray(pcd.points.cpu())\n",
    "    NEIGHBOURS = 10\n",
    "    pcd = cph.geometry.PointCloud(cph.utility.HostVector3fVector(pcd_arr[mask]))\n",
    "    pcd = pcd.remove_statistical_outlier(nb_neighbors=NEIGHBOURS, std_ratio=10.0)\n",
    "    return  pcd[0], meshes_list\n",
    "\n",
    "rbs_pcd, meshes = perform_rbs_on_pointcloud_using_bb(obs, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_CPH_VIZ:\n",
    "    cph.visualization.draw_geometries([rbs_pcd]+meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxelization (GPU) [sec]: 0.008053779602050781\n"
     ]
    }
   ],
   "source": [
    "def convert_pointcloud_to_voxels(pcd):\n",
    "    cubic_size = 2.0\n",
    "    # voxel_resolution = 100.0\n",
    "    voxel_resolution = 30.0\n",
    "\n",
    "\n",
    "    voxel_size = cubic_size / voxel_resolution\n",
    "\n",
    "    # create voxel grid\n",
    "    start = time.time()\n",
    "    voxels = cph.geometry.VoxelGrid.create_from_point_cloud_within_bounds(\n",
    "        pcd,\n",
    "        voxel_size=cubic_size / voxel_resolution,\n",
    "        min_bound=(-cubic_size / 2, -cubic_size / 2, -cubic_size / 2),\n",
    "        max_bound=(cubic_size / 2, cubic_size / 2, cubic_size / 2),\n",
    "    )\n",
    "    elapsed_time = time.time() - start\n",
    "    print(\"Voxelization (GPU) [sec]:\", elapsed_time) # adding outlier removal adds ~25ms\n",
    "\n",
    "\n",
    "    return voxels, voxel_size\n",
    "\n",
    "voxels, voxel_size = convert_pointcloud_to_voxels(rbs_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_CPH_VIZ:\n",
    "    cph.visualization.draw_geometries([voxels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4999754 -1.4988322 -1.555519e-05\n",
      "1.4987465 1.4999558 1.4999748\n",
      "-1.5 -1.5 -0.03333326801657677\n",
      "1.5 1.5 1.5000000653167564\n"
     ]
    }
   ],
   "source": [
    "radius = 0.06\n",
    "VIZ = True\n",
    "\n",
    "if VIZ:\n",
    "    def voxel2sphere(voxels):\n",
    "        global voxel_size, radius\n",
    "        v = voxels.voxels.cpu()\n",
    "        offset = voxels.get_min_bound()\n",
    "\n",
    "        positions = np.array(list(v.keys()))\n",
    "\n",
    "        positions = (positions - np.array([min(positions[:,0]), min(positions[:,1]), min(positions[:,2])]))\n",
    "        positions = positions*voxel_size\n",
    "        positions += (offset + voxel_size/2)\n",
    "\n",
    "        spheres = cph.geometry.TriangleMesh.create_sphere(radius=0.01, resolution=5).translate(positions[0])\n",
    "        for pos in positions[1:]:\n",
    "            spheres += cph.geometry.TriangleMesh.create_sphere(\n",
    "                radius=radius, \n",
    "                resolution=5).translate(pos)\n",
    "        return spheres, positions\n",
    "\n",
    "    spheres, positions  = voxel2sphere(voxels)    \n",
    "\n",
    "    def meshColorscale(mesh):\n",
    "        vertices = np.asarray(mesh.vertices.cpu())\n",
    "        z_values = vertices[:, 2]\n",
    "\n",
    "        # Normalize the z values to range [0, 1]\n",
    "        z_min = z_values.min()\n",
    "        z_max = z_values.max()\n",
    "        z_norm = (z_values - z_min) / (z_max - z_min)\n",
    "\n",
    "        # Create a color map (using a matplotlib colormap, e.g., 'viridis')\n",
    "        cmap = plt.get_cmap('turbo')\n",
    "        colors = cmap(z_norm)[:, :3]  # Get RGB values\n",
    "\n",
    "        # Apply the colors to the mesh\n",
    "        mesh.vertex_colors = cph.utility.Vector3fVector(colors)\n",
    "        return mesh\n",
    "\n",
    "    spheres = meshColorscale(spheres)\n",
    "\n",
    "else:\n",
    "    def voxel2sphere(voxels):\n",
    "        global voxel_size\n",
    "        start = time.time()\n",
    "        v = voxels.voxels.cpu()\n",
    "        offset = voxels.get_min_bound()\n",
    "\n",
    "        positions = np.array(list(v.keys()))\n",
    "\n",
    "        positions = (positions - np.array([min(positions[:,0]), min(positions[:,1]), min(positions[:,2])]))\n",
    "        positions = positions*voxel_size\n",
    "        positions += (offset + voxel_size/2)\n",
    "\n",
    "        elapsed_time = time.time() - start\n",
    "        print(\"Voxel2Sphere (CPU) [sec]:\", elapsed_time) # adding outlier removal adds ~25ms\n",
    "\n",
    "        return positions\n",
    "\n",
    "    positions  = voxel2sphere(voxels)    \n",
    "\n",
    "p = np.array(pcd.points.cpu())\n",
    "print(min(p[:,0]),min(p[:,1]),min(p[:,2]))\n",
    "print(max(p[:,0]),max(p[:,1]),max(p[:,2]))\n",
    "\n",
    "print(min(positions[:,0]),min(positions[:,1]),min(positions[:,2]))\n",
    "print(max(positions[:,0]),max(positions[:,1]),max(positions[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VIZ:\n",
    "    cph.visualization.draw_geometries([spheres])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize workspace\n",
    "# def create_cube_edges(pos_, detect_shell_rad_ ):\n",
    "#     # Define the 8 vertices of the cube\n",
    "#     vertices = np.array([\n",
    "#         [0, 0, 0],  # vertex 0\n",
    "#         [1, 0, 0],  # vertex 1\n",
    "#         [1, 1, 0],  # vertex 2\n",
    "#         [0, 1, 0],  # vertex 3\n",
    "#         [0, 0, 1],  # vertex 4\n",
    "#         [1, 0, 1],  # vertex 5\n",
    "#         [1, 1, 1],  # vertex 6\n",
    "#         [0, 1, 1]   # vertex 7\n",
    "#     ])\n",
    "\n",
    "#     # Define the edges by connecting the vertices\n",
    "#     edges = np.array([\n",
    "#         [0, 1], [1, 2], [2, 3], [3, 0],  # bottom face\n",
    "#         [4, 5], [5, 6], [6, 7], [7, 4],  # top face\n",
    "#         [0, 4], [1, 5], [2, 6], [3, 7]   # vertical edges\n",
    "#     ])\n",
    "\n",
    "#     vertices = detect_shell_rad_*(vertices - np.array([0.5,0.5,0.5])) + pos_\n",
    "\n",
    "#     # Create a LineSet to represent the edges of the cube\n",
    "#     line_set = cph.geometry.LineSet()\n",
    "#     line_set.points = cph.utility.Vector3fVector(vertices)\n",
    "#     line_set.lines = cph.utility.Vector2iVector(edges)\n",
    "\n",
    "#     return line_set\n",
    "\n",
    "# agent_pos = np.array([-0.5,0.0,0.75])\n",
    "# detect_shell_rad_ = 0.5\n",
    "# cph.visualization.draw_geometries([\n",
    "#     voxels, \n",
    "#     create_cube_edges(agent_pos, detect_shell_rad_)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "from torch import tensor\n",
    "import torchvision as tv\n",
    "import torchvision.transforms.functional as tvf\n",
    "from torchvision import io\n",
    "from torch.utils.cpp_extension import load_inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cuda(cuda_src, cpp_src, funcs, opt=False, verbose=False, build_name=\"inline_ext\"):\n",
    "    return load_inline(\n",
    "        cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
    "        extra_cuda_cflags=[\"-O2\"] if opt else [], verbose=verbose, name=build_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/dev/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...\n",
      "The input conditions for extension module inline_ext have changed. Bumping to version 2 and re-building as inline_ext_v2...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/dev/.cache/torch_extensions/py310_cu124/inline_ext/build.ninja...\n",
      "/home/dev/miniconda3/envs/percept/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module inline_ext_v2...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module inline_ext_v2...\n"
     ]
    }
   ],
   "source": [
    "cuda_src = r'''\n",
    "#include <torch/extension.h>\n",
    "#include <stdio.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "\n",
    "\n",
    "__global__ void radial_search_kernel(\n",
    "    const float* points, \n",
    "    const float* target, \n",
    "    float obstacle_rad,\n",
    "    float detect_shell_rad, \n",
    "    int num_points, \n",
    "    int* output, \n",
    "    int* output_count\n",
    "){\n",
    "    int idx = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    if (idx >= num_points) return;\n",
    "    \n",
    "    // get dx, dy, dz\n",
    "    float dx = points[idx * 3] - target[0];\n",
    "    float dy = points[idx * 3 + 1] - target[1];\n",
    "    float dz = points[idx * 3 + 2] - target[2];\n",
    "\n",
    "    float distance = sqrtf(dx * dx + dy * dy + dz * dz) - obstacle_rad;\n",
    "    if (distance <= detect_shell_rad) {\n",
    "        int insert_idx = atomicAdd(output_count, 1);\n",
    "        output[insert_idx] = idx;\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "torch::Tensor radial_search_cuda(\n",
    "    torch::Tensor points, \n",
    "    torch::Tensor target, \n",
    "    float obstacle_rad, \n",
    "    float detect_shell_rad, \n",
    "    int num_points\n",
    ") {\n",
    "    CHECK_INPUT(points);\n",
    "\n",
    "    auto output = torch::zeros({num_points}, torch::dtype(torch::kInt32).device(torch::kCUDA));\n",
    "    auto output_count = torch::zeros({1}, torch::dtype(torch::kInt32).device(torch::kCUDA));\n",
    "\n",
    "    int threads = 256;\n",
    "    int blocks = (num_points + threads - 1) / threads;        \n",
    "    radial_search_kernel<<<blocks, threads>>>(\n",
    "        points.data_ptr<float>(),\n",
    "        target.data_ptr<float>(),\n",
    "        obstacle_rad, \n",
    "        detect_shell_rad,\n",
    "        num_points,\n",
    "        output.data_ptr<int>(),\n",
    "        output_count.data_ptr<int>()\n",
    "    );\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    int result_size = output_count.item<int>();\n",
    "    return output.slice(0, 0, result_size);\n",
    "}\n",
    "'''\n",
    "cpp_src = \"torch::Tensor radial_search_cuda(torch::Tensor points, torch::Tensor target, float obstacle_rad, float detect_shell_rad, int num_points);\"\n",
    "module = load_cuda(cuda_src, cpp_src, ['radial_search_cuda'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1094])\n",
      "CPU times: user 680 μs, sys: 358 μs, total: 1.04 ms\n",
      "Wall time: 777 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "points = torch.from_numpy(positions).contiguous().cuda().flatten().float()\n",
    "target = torch.from_numpy(np.array([0.0,0.0,1.0])).contiguous().cuda().flatten().float()\n",
    "res = module.radial_search_cuda(\n",
    "    points, \n",
    "    target, \n",
    "    0.06,\n",
    "    1.0,\n",
    "    positions.shape[0]\n",
    ").cpu()\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1798, 1820, 1925,  ..., 3158, 3160, 3969], dtype=torch.int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3971, 3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spheres(positions, radius):\n",
    "    spheres = cph.geometry.TriangleMesh.create_sphere(\n",
    "        radius=radius, \n",
    "        resolution=5).translate(positions[0])\n",
    "    for pos in positions[1:]:\n",
    "        spheres += cph.geometry.TriangleMesh.create_sphere(\n",
    "            radius=radius, \n",
    "            resolution=5).translate(pos)\n",
    "    return spheres\n",
    "\n",
    "spheres = create_spheres(positions[res.numpy()], radius)\n",
    "\n",
    "def meshColorscale(mesh):\n",
    "    vertices = np.asarray(mesh.vertices.cpu())\n",
    "    z_values = vertices[:, 2]\n",
    "\n",
    "    # Normalize the z values to range [0, 1]\n",
    "    z_min = z_values.min()\n",
    "    z_max = z_values.max()\n",
    "    z_norm = (z_values - z_min) / (z_max - z_min)\n",
    "\n",
    "    # Create a color map (using a matplotlib colormap, e.g., 'viridis')\n",
    "    cmap = plt.get_cmap('turbo')\n",
    "    colors = cmap(z_norm)[:, :3]  # Get RGB values\n",
    "\n",
    "    # Apply the colors to the mesh\n",
    "    mesh.vertex_colors = cph.utility.Vector3fVector(colors)\n",
    "    return mesh\n",
    "\n",
    "spheres = meshColorscale(spheres)\n",
    "\n",
    "cph.visualization.draw_geometries([spheres])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peract_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
